


## Generations using Initialization with FF:

<details>
  > *With FF model as Imgnet, and also VQmodel as Imgnet:*
  
   > Imgnet-OnlyViTB32,RN101,SLIPB16-cut12-FFimgnet-MixInitialization-ffwt:0.4-iters180-TimeTaken:128.9sec
   ![image](https://user-images.githubusercontent.com/62832721/158542758-7d5b4a55-dffd-4930-8c0a-91afa11e23d4.png)

  **Rest can be found at this link:**
  ```
  https://drive.google.com/drive/folders/16hK9xxsxT09_4tVkuEqD5RruDnMYcViO?usp=sharing
  ```
  </details>

### With FF model as Imgnet, but VQModel as Wikiart:

<details>
  
  ![image](https://user-images.githubusercontent.com/62832721/158545646-56a9d87c-127c-41bd-af6a-bdb4cb4a605e.png)

  
  
  **Rest can be found at this link:**
  ```
  https://drive.google.com/drive/folders/1-dYiEBYvv22CrHSehA0VW6D4HdeziuTc?usp=sharing
  ```
  </details>

## Generations with Initialization as random image:

> Here we can see using perceptors: CLIP-VITB32+CLIP-VITB16, SLIP-VITB16, and no of cuts=12, show good results.

<details>
  
  ![image](https://user-images.githubusercontent.com/62832721/158543974-360f4824-224b-41a6-a679-87596b0668ec.png)

  ![image](https://user-images.githubusercontent.com/62832721/158544349-8cd5aced-4880-4cfe-9d99-93c96b816bf9.png)

  **Rest can be found at this link:**
  
  ```
  https://drive.google.com/drive/folders/1-GtpsxVNhUDJag6NGKqIF7Q1Uwe3Z76Y?usp=sharing
  ```
  
  </details>
